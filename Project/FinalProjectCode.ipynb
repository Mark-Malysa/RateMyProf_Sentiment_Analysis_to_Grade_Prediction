{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0s/fwdq9_nj4vzd6ys2nx7330tw0000gn/T/ipykernel_93901/1350687843.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataCollector:\n",
    "    \n",
    "    def load_existing_data(self, filepath: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Load existing review data from a JSON file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to the JSON file\n",
    "            \n",
    "        Returns:\n",
    "            List of review dictionaries\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Flatten the nested structure\n",
    "            reviews = []\n",
    "            for course_reviews in data:\n",
    "                reviews.extend(course_reviews)\n",
    "            \n",
    "            #logger.info(f\"Successfully loaded {len(reviews)} reviews from {filepath}\")\n",
    "            return reviews\n",
    "        except Exception as e:\n",
    "            #logger.error(f\"Error loading data: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def parse_json_string(self, json_str):\n",
    "        \"\"\"\n",
    "        Parse a JSON string into a dictionary.\n",
    "        \n",
    "        Args:\n",
    "            json_str: JSON string to parse\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing the parsed data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if pd.isna(json_str):\n",
    "                return {}\n",
    "            # Use ast.literal_eval to safely evaluate the string representation of a dictionary\n",
    "            return ast.literal_eval(json_str)\n",
    "        except:\n",
    "            return {}\n",
    "    \n",
    "    def save_data(self, data: List[Dict[str, Any]], filepath: str):\n",
    "        \"\"\"\n",
    "        Save data to a CSV file.\n",
    "        \n",
    "        Args:\n",
    "            data: List of review dictionaries\n",
    "            filepath: Output file path\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Convert list of dictionaries to DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            # Clean and standardize columns\n",
    "            df = df.rename(columns={\n",
    "                'Quality': 'rating',\n",
    "                'Difficulty': 'difficulty',\n",
    "                'Grade': 'grade',\n",
    "                'Comment': 'text',\n",
    "                'professor': 'professor_name'\n",
    "            })\n",
    "            \n",
    "            # Convert numeric columns\n",
    "            df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "            df['difficulty'] = pd.to_numeric(df['difficulty'], errors='coerce')\n",
    "            \n",
    "            # Save to CSV\n",
    "            df.to_csv(filepath, index=False)\n",
    "            #logger.info(f\"Saved {len(df)} reviews to {filepath}\")\n",
    "        except Exception as e:\n",
    "            #logger.error(f\"Error saving data: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def load_and_split_data(self):\n",
    "        \"\"\"\n",
    "        Load existing data and split into training and test sets.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load data\n",
    "            data = self.load_existing_data(\"datasets/all_reviews.json\")\n",
    "            \n",
    "            # Split into training and test sets (80-20 split)\n",
    "            train_size = int(len(data) * 0.8)\n",
    "            training_data = data[:train_size]\n",
    "            test_data = data[train_size:]\n",
    "            \n",
    "            # Save the splits\n",
    "            self.save_data(training_data, \"data/raw/training_reviews.csv\")\n",
    "            self.save_data(test_data, \"data/raw/test_reviews.csv\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            #logger.error(f\"Error in load_and_split_data: {e}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    collector = DataCollector()\n",
    "    collector.load_and_split_data()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/markmalysa/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/markmalysa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import logging\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        # Initialize NLTK components\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "    def load_data(self, filepath: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load the raw data from CSV file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to the CSV file\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame containing the raw data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            logger.info(f\"Successfully loaded data from {filepath}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Clean and preprocess text data.\n",
    "        \n",
    "        Args:\n",
    "            text: Raw text string\n",
    "            \n",
    "        Returns:\n",
    "            Cleaned text string\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "            \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Split into words\n",
    "        words = text.split()\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        cleaned_words = [\n",
    "            self.lemmatizer.lemmatize(word)\n",
    "            for word in words\n",
    "            if word not in self.stop_words\n",
    "        ]\n",
    "        \n",
    "        return ' '.join(cleaned_words)\n",
    "    \n",
    "    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Preprocess the entire dataset.\n",
    "        \n",
    "        Args:\n",
    "            df: Raw DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed DataFrame\n",
    "        \"\"\"\n",
    "        # Create a copy to avoid modifying the original\n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        # Clean text data\n",
    "        if 'text' in df_processed.columns:\n",
    "            df_processed['cleaned_text'] = df_processed['text'].apply(self.clean_text)\n",
    "        \n",
    "        # Handle missing values\n",
    "        df_processed = df_processed.dropna(subset=['rating', 'difficulty'])\n",
    "        \n",
    "        # Convert grade to numerical values if needed\n",
    "        if 'grade' in df_processed.columns:\n",
    "            grade_mapping = {\n",
    "                'A+': 4.0, 'A': 4.0, 'A-': 3.7,\n",
    "                'B+': 3.3, 'B': 3.0, 'B-': 2.7,\n",
    "                'C+': 2.3, 'C': 2.0, 'C-': 1.7,\n",
    "                'D+': 1.3, 'D': 1.0, 'D-': 0.7,\n",
    "                'F': 0.0\n",
    "            }\n",
    "            df_processed['grade_numerical'] = df_processed['grade'].map(grade_mapping)\n",
    "        \n",
    "        return df_processed\n",
    "    \n",
    "    def save_processed_data(self, df: pd.DataFrame, filepath: str):\n",
    "        \"\"\"\n",
    "        Save processed data to CSV file.\n",
    "        \n",
    "        Args:\n",
    "            df: Processed DataFrame\n",
    "            filepath: Output file path\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df.to_csv(filepath, index=False)\n",
    "            logger.info(f\"Successfully saved processed data to {filepath}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving processed data: {e}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    # # Example usage\n",
    "    preprocessor = DataPreprocessor()\n",
    "    \n",
    "    # # Load raw data\n",
    "    # raw_data = preprocessor.load_data(\"data/raw/professor_reviews.csv\")\n",
    "    \n",
    "    # # Preprocess data\n",
    "    # processed_data = preprocessor.preprocess_data(raw_data)\n",
    "    \n",
    "    # # Save processed data\n",
    "    # preprocessor.save_processed_data(processed_data, \"data/processed/processed_reviews.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import logging\n",
    "from typing import Tuple, Dict, Any\n",
    "import pickle\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(max_features=5000)\n",
    "        self.model = None\n",
    "        self.model_type = None\n",
    "    \n",
    "    def prepare_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Prepare data for sentiment analysis.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame containing cleaned text and ratings\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (X, y) for model training\n",
    "        \"\"\"\n",
    "        # Convert ratings to binary sentiment (positive/negative)\n",
    "        df['sentiment'] = df['rating'].apply(lambda x: 1 if x >= 3.5 else 0)\n",
    "        \n",
    "        # Vectorize text\n",
    "        if not hasattr(self.vectorizer, 'vocabulary_'):\n",
    "            # Only fit the vectorizer if it hasn't been fit before\n",
    "            X = self.vectorizer.fit_transform(df['cleaned_text'])\n",
    "        else:\n",
    "            # Use transform only if the vectorizer was already fit\n",
    "            X = self.vectorizer.transform(df['cleaned_text'])\n",
    "            \n",
    "        y = df['sentiment'].values\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def train_model(self, X: np.ndarray, y: np.ndarray, model_type: str = 'nb') -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Train a sentiment analysis model.\n",
    "        \n",
    "        Args:\n",
    "            X: Feature matrix\n",
    "            y: Target vector\n",
    "            model_type: Type of model to train ('nb' for Naive Bayes, 'lr' for Logistic Regression)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing model performance metrics\n",
    "        \"\"\"\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        if model_type == 'nb':\n",
    "            self.model = MultinomialNB()\n",
    "            self.model_type = 'Naive Bayes'\n",
    "        elif model_type == 'lr':\n",
    "            self.model = LogisticRegression(max_iter=1000)\n",
    "            self.model_type = 'Logistic Regression'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model type. Use 'nb' or 'lr'\")\n",
    "        \n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate model\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        logger.info(f\"Model: {self.model_type}\")\n",
    "        logger.info(f\"Accuracy: {accuracy:.4f}\")\n",
    "        logger.info(f\"F1 Score: {f1:.4f}\")\n",
    "        logger.info(\"\\nClassification Report:\")\n",
    "        logger.info(classification_report(y_test, y_pred))\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'classification_report': classification_report(y_test, y_pred)\n",
    "        }\n",
    "    \n",
    "    def evaluate_model(self, X: np.ndarray, y: np.ndarray) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Evaluate the trained model on new data.\n",
    "        \n",
    "        Args:\n",
    "            X: Feature matrix\n",
    "            y: Target vector\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing model performance metrics\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained. Call train_model first.\")\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = self.model.predict(X)\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        f1 = f1_score(y, y_pred)\n",
    "        \n",
    "        logger.info(f\"Model Evaluation ({self.model_type}):\")\n",
    "        logger.info(f\"Accuracy: {accuracy:.4f}\")\n",
    "        logger.info(f\"F1 Score: {f1:.4f}\")\n",
    "        logger.info(\"\\nClassification Report:\")\n",
    "        logger.info(classification_report(y, y_pred))\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'classification_report': classification_report(y, y_pred)\n",
    "        }\n",
    "    \n",
    "    def predict_sentiment(self, text: str) -> Tuple[int, float]:\n",
    "        \"\"\"\n",
    "        Predict sentiment for a new text.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to analyze\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (predicted class, probability)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained. Call train_model first.\")\n",
    "        \n",
    "        # Vectorize text\n",
    "        X = self.vectorizer.transform([text])\n",
    "        \n",
    "        # Predict\n",
    "        pred_class = self.model.predict(X)[0]\n",
    "        pred_prob = self.model.predict_proba(X)[0][1]\n",
    "        \n",
    "        return pred_class, pred_prob\n",
    "    \n",
    "    def save_model(self, model_path: str, vectorizer_path: str):\n",
    "        \"\"\"\n",
    "        Save trained model and vectorizer.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to save model\n",
    "            vectorizer_path: Path to save vectorizer\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump(self.model, f)\n",
    "            with open(vectorizer_path, 'wb') as f:\n",
    "                pickle.dump(self.vectorizer, f)\n",
    "            logger.info(f\"Model and vectorizer saved to {model_path} and {vectorizer_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def load_model(self, model_path: str, vectorizer_path: str):\n",
    "        \"\"\"\n",
    "        Load trained model and vectorizer.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to load model from\n",
    "            vectorizer_path: Path to load vectorizer from\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(model_path, 'rb') as f:\n",
    "                self.model = pickle.load(f)\n",
    "            with open(vectorizer_path, 'rb') as f:\n",
    "                self.vectorizer = pickle.load(f)\n",
    "            logger.info(\"Model and vectorizer loaded successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    analyzer = SentimentAnalyzer()\n",
    "    \n",
    "    # # Load processed data\n",
    "    # df = pd.read_csv(\"data/processed/processed_reviews.csv\")\n",
    "    \n",
    "    # # Prepare data\n",
    "    # X, y = analyzer.prepare_data(df)\n",
    "    \n",
    "    # # Train model\n",
    "    # metrics = analyzer.train_model(X, y, model_type='nb')\n",
    "    \n",
    "    # # Save model\n",
    "    # analyzer.save_model(\n",
    "    #     \"models/sentiment_model.pkl\",\n",
    "    #     \"models/vectorizer.pkl\"\n",
    "    # )\n",
    "    \n",
    "    # # Example prediction\n",
    "    # sample_text = \"This professor is amazing and very helpful!\"\n",
    "    # pred_class, pred_prob = analyzer.predict_sentiment(sample_text)\n",
    "    # logger.info(f\"Sample text: {sample_text}\")\n",
    "    # logger.info(f\"Predicted sentiment: {'Positive' if pred_class == 1 else 'Negative'}\")\n",
    "    # logger.info(f\"Confidence: {pred_prob:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from textblob import TextBlob\n",
    "import logging\n",
    "from typing import Tuple, Dict, Any\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class GradePredictor:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.base_features = ['rating', 'difficulty', 'sentiment_score']\n",
    "        self.feature_columns = self.base_features.copy()\n",
    "        self.professor_features = ['review_count', 'avg_rating', 'avg_difficulty']\n",
    "        \n",
    "    def calculate_sentiment_score(self, text):\n",
    "        \"\"\"Calculate sentiment score for a given text.\"\"\"\n",
    "        try:\n",
    "            return TextBlob(str(text)).sentiment.polarity\n",
    "        except:\n",
    "            return 0.0\n",
    "        \n",
    "    def prepare_features(self, df: pd.DataFrame, is_training: bool = True):\n",
    "        \"\"\"\n",
    "        Prepare features for model training or prediction.\n",
    "        \n",
    "        Args:\n",
    "            df: Input DataFrame\n",
    "            is_training: Whether this is for training (True) or prediction (False)\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (X, y) where X is features DataFrame and y is target Series\n",
    "        \"\"\"\n",
    "        # Create a copy to avoid modifying the original\n",
    "        df_features = df.copy()\n",
    "        \n",
    "        # Calculate sentiment scores\n",
    "        logger.info(\"Calculating sentiment scores...\")\n",
    "        df_features['sentiment_score'] = df_features['cleaned_text'].apply(self.calculate_sentiment_score)\n",
    "        \n",
    "        # Create professor-level features if professor_name is available\n",
    "        if 'professor_name' in df_features.columns:\n",
    "            prof_stats = df_features.groupby('professor_name').agg({\n",
    "                'rating': ['count', 'mean'],\n",
    "                'difficulty': 'mean'\n",
    "            }).reset_index()\n",
    "            prof_stats.columns = ['professor_name', 'review_count', 'avg_rating', 'avg_difficulty']\n",
    "            \n",
    "            # Merge back to main DataFrame\n",
    "            df_features = df_features.merge(prof_stats, on='professor_name', how='left')\n",
    "            \n",
    "            # Add these to feature columns if in training mode\n",
    "            if is_training:\n",
    "                self.feature_columns = self.base_features + self.professor_features\n",
    "        \n",
    "        # Convert grade to numerical values if needed\n",
    "        if 'grade' in df_features.columns:\n",
    "            grade_mapping = {\n",
    "                'A+': 4.0, 'A': 4.0, 'A-': 3.7,\n",
    "                'B+': 3.3, 'B': 3.0, 'B-': 2.7,\n",
    "                'C+': 2.3, 'C': 2.0, 'C-': 1.7,\n",
    "                'D+': 1.3, 'D': 1.0, 'D-': 0.7,\n",
    "                'F': 0.0\n",
    "            }\n",
    "            df_features['grade_numerical'] = df_features['grade'].map(grade_mapping)\n",
    "        \n",
    "        # Add missing professor-level features if needed\n",
    "        for feature in self.feature_columns:\n",
    "            if feature not in df_features.columns:\n",
    "                df_features[feature] = 0.0  # Use default value for missing features\n",
    "        \n",
    "        # Prepare feature matrix\n",
    "        X = df_features[self.feature_columns].copy()\n",
    "        \n",
    "        # Handle missing values\n",
    "        X = X.fillna(X.mean())\n",
    "        \n",
    "        # Scale features\n",
    "        if is_training:\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "        else:\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        X_scaled = pd.DataFrame(X_scaled, columns=self.feature_columns)\n",
    "        \n",
    "        if 'grade_numerical' in df_features.columns:\n",
    "            y = df_features['grade_numerical'].fillna(df_features['grade_numerical'].mean())\n",
    "            return X_scaled, y\n",
    "        else:\n",
    "            return X_scaled, None\n",
    "    \n",
    "    def train(self, train_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Train the grade prediction model.\n",
    "        \n",
    "        Args:\n",
    "            train_df: Training DataFrame\n",
    "        \"\"\"\n",
    "        logger.info(\"Preparing features for training...\")\n",
    "        X, y = self.prepare_features(train_df, is_training=True)\n",
    "        \n",
    "        # Drop rows with missing target values\n",
    "        mask = ~y.isna()\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "        \n",
    "        logger.info(\"Training model...\")\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        train_pred = self.model.predict(X)\n",
    "        train_rmse = np.sqrt(np.mean((y - train_pred) ** 2))\n",
    "        logger.info(f\"Training RMSE: {train_rmse:.3f}\")\n",
    "    \n",
    "    def evaluate_model(self, test_df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Evaluate model performance on test data.\n",
    "        \n",
    "        Args:\n",
    "            test_df: Test DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing evaluation metrics\n",
    "        \"\"\"\n",
    "        X_test, y_test = self.prepare_features(test_df, is_training=False)\n",
    "        \n",
    "        # Drop rows with missing target values\n",
    "        mask = ~y_test.isna()\n",
    "        X_test = X_test[mask]\n",
    "        y_test = y_test[mask]\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))\n",
    "        mae = np.mean(np.abs(y_test - y_pred))\n",
    "        r2 = self.model.score(X_test, y_test)\n",
    "        \n",
    "        metrics = {\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Test RMSE: {rmse:.3f}\")\n",
    "        logger.info(f\"Test MAE: {mae:.3f}\")\n",
    "        logger.info(f\"Test R2: {r2:.3f}\")\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def predict_grade(self, features_dict: dict) -> tuple:\n",
    "        \"\"\"\n",
    "        Predict grade for new data.\n",
    "        \n",
    "        Args:\n",
    "            features_dict: Dictionary containing feature values\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (predicted_grade, confidence_interval)\n",
    "        \"\"\"\n",
    "        # Create DataFrame from features\n",
    "        df = pd.DataFrame([features_dict])\n",
    "        \n",
    "        # Prepare features\n",
    "        X, _ = self.prepare_features(df, is_training=False)\n",
    "        \n",
    "        # Make prediction\n",
    "        pred = self.model.predict(X)[0]\n",
    "        \n",
    "        # Calculate confidence interval using prediction std\n",
    "        predictions = []\n",
    "        for estimator in self.model.estimators_:\n",
    "            predictions.append(estimator.predict(X)[0])\n",
    "        \n",
    "        ci_lower = np.percentile(predictions, 2.5)\n",
    "        ci_upper = np.percentile(predictions, 97.5)\n",
    "        \n",
    "        # Convert numerical grade to letter grade\n",
    "        grade_mapping = {\n",
    "            4.0: 'A',\n",
    "            3.7: 'A-',\n",
    "            3.3: 'B+',\n",
    "            3.0: 'B',\n",
    "            2.7: 'B-',\n",
    "            2.3: 'C+',\n",
    "            2.0: 'C',\n",
    "            1.7: 'C-',\n",
    "            1.3: 'D+',\n",
    "            1.0: 'D',\n",
    "            0.7: 'D-',\n",
    "            0.0: 'F'\n",
    "        }\n",
    "        \n",
    "        # Find closest grade\n",
    "        pred_letter = min(grade_mapping.items(), key=lambda x: abs(x[0] - pred))[1]\n",
    "        ci_lower_letter = min(grade_mapping.items(), key=lambda x: abs(x[0] - ci_lower))[1]\n",
    "        ci_upper_letter = min(grade_mapping.items(), key=lambda x: abs(x[0] - ci_upper))[1]\n",
    "        \n",
    "        return (pred_letter, (ci_lower_letter, ci_upper_letter)), (pred, (ci_lower, ci_upper))\n",
    "    \n",
    "    def save_model(self, model_path: str):\n",
    "        \"\"\"Save the trained model to disk.\"\"\"\n",
    "        joblib.dump((self.model, self.scaler, self.feature_columns), model_path)\n",
    "        logger.info(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    def load_model(self, model_path: str):\n",
    "        \"\"\"Load a trained model from disk.\"\"\"\n",
    "        self.model, self.scaler, self.feature_columns = joblib.load(model_path)\n",
    "        logger.info(f\"Model loaded from {model_path}\")\n",
    "            \n",
    "    def get_feature_importance(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get feature importance scores from the model.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame containing feature names and their importance scores\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'model') or not hasattr(self.model, 'feature_importances_'):\n",
    "            raise ValueError(\"Model not trained or does not support feature importance\")\n",
    "            \n",
    "        importance_scores = self.model.feature_importances_\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': self.feature_columns,\n",
    "            'importance': importance_scores\n",
    "        })\n",
    "        \n",
    "        # Sort by importance in descending order\n",
    "        feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "        \n",
    "        return feature_importance\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    \n",
    "    # Load processed data\n",
    "    train_data = pd.read_csv(\"data/processed/processed_training_reviews.csv\")\n",
    "    test_data = pd.read_csv(\"data/processed/processed_test_reviews.csv\")\n",
    "    \n",
    "    # # Initialize and train model\n",
    "    # predictor = GradePredictor()\n",
    "    # predictor.train(train_data)\n",
    "    \n",
    "    # # Evaluate model\n",
    "    # metrics = predictor.evaluate_model(test_data)\n",
    "    \n",
    "    # # Save model\n",
    "    # predictor.save_model(\"models/grade_predictor.pkl\")\n",
    "    \n",
    "    # # Example prediction\n",
    "    # sample_features = {\n",
    "    #     'rating': 4.5,\n",
    "    #     'difficulty': 3.0,\n",
    "    #     'cleaned_text': \"The professor was very helpful and explained concepts clearly.\"\n",
    "    # }\n",
    "    \n",
    "    # (pred_letter, ci_letter), (pred_num, ci_num) = predictor.predict_grade(sample_features)\n",
    "    # logger.info(f\"Predicted grade (letter): {pred_letter}\")\n",
    "    # logger.info(f\"95% Confidence Interval (letter): ({ci_letter[0]}, {ci_letter[1]})\")\n",
    "    # logger.info(f\"Predicted grade (numerical): {pred_num:.2f}\")\n",
    "    # logger.info(f\"95% Confidence Interval (numerical): ({ci_num[0]:.2f}, {ci_num[1]:.2f})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Optional\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DataVisualizer:\n",
    "    def __init__(self, output_dir: str = \"visualizations\"):\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Set style\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.set_palette(\"husl\")\n",
    "    \n",
    "    def plot_sentiment_distribution(self, df: pd.DataFrame, suffix: str = \"\"):\n",
    "        \"\"\"\n",
    "        Plot distribution of sentiment scores.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame containing sentiment scores\n",
    "            suffix: Suffix to add to output filename\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(data=df, x='sentiment_score', bins=20)\n",
    "        plt.title('Distribution of Sentiment Scores')\n",
    "        plt.xlabel('Sentiment Score')\n",
    "        plt.ylabel('Count')\n",
    "        plt.savefig(f\"{self.output_dir}/sentiment_distribution{suffix}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_grade_correlation(self, df: pd.DataFrame, suffix: str = \"\"):\n",
    "        \"\"\"\n",
    "        Plot correlation between sentiment and grades.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame containing sentiment scores and grades\n",
    "            suffix: Suffix to add to output filename\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(data=df, x='sentiment_score', y='grade_numerical')\n",
    "        plt.title('Correlation between Sentiment and Grades')\n",
    "        plt.xlabel('Sentiment Score')\n",
    "        plt.ylabel('Grade')\n",
    "        plt.savefig(f\"{self.output_dir}/grade_correlation{suffix}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_difficulty_rating(self, df: pd.DataFrame, suffix: str = \"\"):\n",
    "        \"\"\"\n",
    "        Plot relationship between difficulty and rating.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame containing difficulty and rating scores\n",
    "            suffix: Suffix to add to output filename\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(data=df, x='difficulty', y='rating')\n",
    "        plt.title('Relationship between Difficulty and Rating')\n",
    "        plt.xlabel('Difficulty')\n",
    "        plt.ylabel('Rating')\n",
    "        plt.savefig(f\"{self.output_dir}/difficulty_rating{suffix}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_department_comparison(self, df: pd.DataFrame, suffix: str = \"\"):\n",
    "        \"\"\"\n",
    "        Plot comparison of ratings across departments.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame containing department and rating information\n",
    "            suffix: Suffix to add to output filename\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=df, x='department', y='rating')\n",
    "        plt.title('Rating Distribution by Department')\n",
    "        plt.xlabel('Department')\n",
    "        plt.ylabel('Rating')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.output_dir}/department_comparison{suffix}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_feature_importance(self, importance_df: pd.DataFrame, suffix: str = \"\"):\n",
    "        \"\"\"\n",
    "        Plot feature importance scores.\n",
    "        \n",
    "        Args:\n",
    "            importance_df: DataFrame containing feature importance scores\n",
    "            suffix: Suffix to add to output filename\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(data=importance_df, x='importance', y='feature')\n",
    "        plt.title('Feature Importance for Grade Prediction')\n",
    "        plt.xlabel('Importance Score')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.output_dir}/feature_importance{suffix}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_sentiment_trends(self, df: pd.DataFrame, suffix: str = \"\"):\n",
    "        \"\"\"\n",
    "        Plot sentiment trends over time.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame containing sentiment scores and dates\n",
    "            suffix: Suffix to add to output filename\n",
    "        \"\"\"\n",
    "        # Convert date column to datetime if needed\n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            df = df.sort_values('date')\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.lineplot(data=df, x='date', y='sentiment_score')\n",
    "            plt.title('Sentiment Trends Over Time')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Average Sentiment Score')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{self.output_dir}/sentiment_trends{suffix}.png\")\n",
    "            plt.close()\n",
    "    \n",
    "    def create_correlation_matrix(self, df: pd.DataFrame, features: List[str], suffix: str = \"\"):\n",
    "        \"\"\"\n",
    "        Create correlation matrix heatmap.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame containing features\n",
    "            features: List of features to include in correlation matrix\n",
    "            suffix: Suffix to add to output filename\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        corr_matrix = df[features].corr()\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "        plt.title('Feature Correlation Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.output_dir}/correlation_matrix{suffix}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_model_comparison(self, train_metrics: Dict[str, float], test_metrics: Dict[str, float], \n",
    "                            model_name: str, suffix: str = \"\"):\n",
    "        \"\"\"\n",
    "        Plot comparison of model performance on training and test data.\n",
    "        \n",
    "        Args:\n",
    "            train_metrics: Dictionary of training metrics\n",
    "            test_metrics: Dictionary of test metrics\n",
    "            model_name: Name of the model\n",
    "            suffix: Suffix to add to output filename\n",
    "        \"\"\"\n",
    "        metrics = ['accuracy', 'f1_score', 'rmse', 'r2_score']\n",
    "        train_values = [train_metrics.get(m, 0) for m in metrics]\n",
    "        test_values = [test_metrics.get(m, 0) for m in metrics]\n",
    "        \n",
    "        x = np.arange(len(metrics))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(x - width/2, train_values, width, label='Training')\n",
    "        plt.bar(x + width/2, test_values, width, label='Test')\n",
    "        \n",
    "        plt.xlabel('Metric')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title(f'{model_name} Performance Comparison')\n",
    "        plt.xticks(x, metrics)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.output_dir}/model_comparison_{model_name}{suffix}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_actual_vs_predicted(self, y_true, y_pred, suffix=''):\n",
    "        \"\"\"\n",
    "        Plot actual vs. predicted grades.\n",
    "        \n",
    "        Args:\n",
    "            y_true (array-like): Actual grades.\n",
    "            y_pred (array-like): Predicted grades.\n",
    "            suffix (str): Suffix for the output filename.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(y_true, y_pred, alpha=0.5)\n",
    "        plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
    "        plt.xlabel('Actual Grades')\n",
    "        plt.ylabel('Predicted Grades')\n",
    "        plt.title('Actual vs. Predicted Grades')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.output_dir, f'actual_vs_predicted{suffix}.png'))\n",
    "        plt.close()\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    visualizer = DataVisualizer()\n",
    "    \n",
    "    # # Load processed data\n",
    "    # training_df = pd.read_csv(\"data/processed/processed_training_reviews.csv\")\n",
    "    # test_df = pd.read_csv(\"data/processed/processed_test_reviews.csv\")\n",
    "    \n",
    "    # # Create visualizations for training data\n",
    "    # visualizer.plot_sentiment_distribution(training_df, suffix=\"_train\")\n",
    "    # visualizer.plot_grade_correlation(training_df, suffix=\"_train\")\n",
    "    # visualizer.plot_difficulty_rating(training_df, suffix=\"_train\")\n",
    "    # visualizer.plot_department_comparison(training_df, suffix=\"_train\")\n",
    "    \n",
    "    # # Create visualizations for test data\n",
    "    # visualizer.plot_sentiment_distribution(test_df, suffix=\"_test\")\n",
    "    # visualizer.plot_grade_correlation(test_df, suffix=\"_test\")\n",
    "    # visualizer.plot_difficulty_rating(test_df, suffix=\"_test\")\n",
    "    \n",
    "    # # Load feature importance data\n",
    "    # importance_df = pd.read_csv(\"models/feature_importance.csv\")\n",
    "    # visualizer.plot_feature_importance(importance_df)\n",
    "    \n",
    "    # # Create correlation matrices\n",
    "    # features = ['rating', 'difficulty', 'sentiment_score', 'grade_numerical']\n",
    "    # visualizer.create_correlation_matrix(training_df, features, suffix=\"_train\")\n",
    "    # visualizer.create_correlation_matrix(test_df, features, suffix=\"_test\")\n",
    "    \n",
    "    # # Plot sentiment trends if date data is available\n",
    "    # if 'date' in training_df.columns:\n",
    "    #     visualizer.plot_sentiment_trends(training_df, suffix=\"_train\")\n",
    "    # if 'date' in test_df.columns:\n",
    "    #     visualizer.plot_sentiment_trends(test_df, suffix=\"_test\")\n",
    "\n",
    "    # # After model evaluation\n",
    "    # y_pred = model.predict(X_test_scaled)\n",
    "    # visualizer.plot_actual_vs_predicted(y_test, y_pred, suffix=\"_test\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the main function for to run the Random Forrest Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting data collection...\n",
      "INFO:__main__:Loading and splitting data...\n",
      "INFO:__main__:Starting data preprocessing...\n",
      "INFO:__main__:Preprocessing training data...\n",
      "INFO:__main__:Successfully loaded data from data/raw/training_reviews.csv\n",
      "INFO:__main__:Successfully saved processed data to data/processed/processed_training_reviews.csv\n",
      "INFO:__main__:Preprocessing test data...\n",
      "INFO:__main__:Successfully loaded data from data/raw/test_reviews.csv\n",
      "INFO:__main__:Successfully saved processed data to data/processed/processed_test_reviews.csv\n",
      "INFO:__main__:Starting sentiment analysis...\n",
      "INFO:__main__:Training sentiment model...\n",
      "INFO:__main__:Model: Naive Bayes\n",
      "INFO:__main__:Accuracy: 0.7370\n",
      "INFO:__main__:F1 Score: 0.8446\n",
      "INFO:__main__:\n",
      "Classification Report:\n",
      "INFO:__main__:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.08      0.14       153\n",
      "           1       0.73      1.00      0.84       387\n",
      "\n",
      "    accuracy                           0.74       540\n",
      "   macro avg       0.83      0.54      0.49       540\n",
      "weighted avg       0.79      0.74      0.65       540\n",
      "\n",
      "INFO:__main__:Model and vectorizer saved to models/sentiment_model.pkl and models/vectorizer.pkl\n",
      "INFO:__main__:Evaluating sentiment model on test data...\n",
      "INFO:__main__:Model Evaluation (Naive Bayes):\n",
      "INFO:__main__:Accuracy: 0.8000\n",
      "INFO:__main__:F1 Score: 0.8880\n",
      "INFO:__main__:\n",
      "Classification Report:\n",
      "INFO:__main__:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.07       140\n",
      "           1       0.80      1.00      0.89       535\n",
      "\n",
      "    accuracy                           0.80       675\n",
      "   macro avg       0.90      0.52      0.48       675\n",
      "weighted avg       0.84      0.80      0.72       675\n",
      "\n",
      "INFO:__main__:Adding sentiment scores to DataFrames...\n",
      "INFO:__main__:Starting grade prediction modeling...\n",
      "INFO:__main__:Training grade prediction model...\n",
      "INFO:__main__:Preparing features for training...\n",
      "INFO:__main__:Calculating sentiment scores...\n",
      "INFO:__main__:Training model...\n",
      "INFO:__main__:Training RMSE: 0.098\n",
      "INFO:__main__:Evaluating grade prediction model...\n",
      "INFO:__main__:Calculating sentiment scores...\n",
      "INFO:__main__:Test RMSE: 0.259\n",
      "INFO:__main__:Test MAE: 0.144\n",
      "INFO:__main__:Test R2: -0.085\n",
      "INFO:__main__:Model saved to models/grade_predictor.pkl\n",
      "INFO:__main__:Calculating sentiment scores...\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "INFO:__main__:Example Prediction:\n",
      "INFO:__main__:Predicted grade: ('A-', ('B+', 'A'))\n",
      "INFO:__main__:95% Confidence Interval: (3.7239365558912407, (3.3, 4.0))\n",
      "INFO:__main__:Creating visualizations...\n",
      "INFO:__main__:Visualizing training data...\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/seaborn/categorical.py:640: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "INFO:__main__:Visualizing test data...\n",
      "INFO:__main__:Calculating sentiment scores...\n",
      "INFO:__main__:Test RMSE: 0.259\n",
      "INFO:__main__:Test MAE: 0.144\n",
      "INFO:__main__:Test R2: -0.085\n",
      "INFO:__main__:Calculating sentiment scores...\n",
      "INFO:__main__:Analysis pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from data_collection import DataCollector\n",
    "# from preprocessing import DataPreprocessor\n",
    "# from src.models.sentiment_analysis import SentimentAnalyzer\n",
    "# from src.models.predictive_modeling import GradePredictor\n",
    "# from src.visualization.visualization import DataVisualizer\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def add_sentiment_scores(df: pd.DataFrame, sentiment_analyzer: SentimentAnalyzer) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add sentiment scores to the DataFrame.\n",
    "    \"\"\"\n",
    "    # Get sentiment probabilities for each review\n",
    "    X = sentiment_analyzer.vectorizer.transform(df['cleaned_text'])\n",
    "    probabilities = sentiment_analyzer.model.predict_proba(X)\n",
    "    df['sentiment_score'] = probabilities[:, 1]  # Probability of positive sentiment\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the entire analysis pipeline.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Data Collection\n",
    "        logger.info(\"Starting data collection...\")\n",
    "        logger.info(\"Loading and splitting data...\")\n",
    "        collector = DataCollector()\n",
    "        collector.load_and_split_data()\n",
    "        \n",
    "        # Step 2: Data Preprocessing\n",
    "        logger.info(\"Starting data preprocessing...\")\n",
    "        preprocessor = DataPreprocessor()\n",
    "        \n",
    "        # Preprocess training data\n",
    "        logger.info(\"Preprocessing training data...\")\n",
    "        train_df = preprocessor.load_data(\"data/raw/training_reviews.csv\")\n",
    "        processed_train_df = preprocessor.preprocess_data(train_df)\n",
    "        preprocessor.save_processed_data(processed_train_df, \"data/processed/processed_training_reviews.csv\")\n",
    "        \n",
    "        # Preprocess test data\n",
    "        logger.info(\"Preprocessing test data...\")\n",
    "        test_df = preprocessor.load_data(\"data/raw/test_reviews.csv\")\n",
    "        processed_test_df = preprocessor.preprocess_data(test_df)\n",
    "        preprocessor.save_processed_data(processed_test_df, \"data/processed/processed_test_reviews.csv\")\n",
    "        \n",
    "        # Step 3: Sentiment Analysis\n",
    "        logger.info(\"Starting sentiment analysis...\")\n",
    "        sentiment_analyzer = SentimentAnalyzer()\n",
    "        \n",
    "        # Train sentiment model\n",
    "        logger.info(\"Training sentiment model...\")\n",
    "        X_train, y_train = sentiment_analyzer.prepare_data(processed_train_df)\n",
    "        metrics = sentiment_analyzer.train_model(X_train, y_train, model_type='nb')\n",
    "        sentiment_analyzer.save_model(\"models/sentiment_model.pkl\", \"models/vectorizer.pkl\")\n",
    "        \n",
    "        # Evaluate sentiment model\n",
    "        logger.info(\"Evaluating sentiment model on test data...\")\n",
    "        X_test, y_test = sentiment_analyzer.prepare_data(processed_test_df)\n",
    "        test_metrics = sentiment_analyzer.evaluate_model(X_test, y_test)\n",
    "        \n",
    "        # Add sentiment scores to DataFrames\n",
    "        logger.info(\"Adding sentiment scores to DataFrames...\")\n",
    "        processed_train_df = add_sentiment_scores(processed_train_df, sentiment_analyzer)\n",
    "        processed_test_df = add_sentiment_scores(processed_test_df, sentiment_analyzer)\n",
    "        \n",
    "        # Step 4: Grade Prediction\n",
    "        logger.info(\"Starting grade prediction modeling...\")\n",
    "        predictor = GradePredictor()\n",
    "        \n",
    "        # Train grade prediction model\n",
    "        logger.info(\"Training grade prediction model...\")\n",
    "        predictor.train(processed_train_df)\n",
    "        \n",
    "        # Evaluate grade prediction model\n",
    "        logger.info(\"Evaluating grade prediction model...\")\n",
    "        metrics = predictor.evaluate_model(processed_test_df)\n",
    "        \n",
    "        # Save the model\n",
    "        predictor.save_model(\"models/grade_predictor.pkl\")\n",
    "        \n",
    "        # Example prediction\n",
    "        sample_features = {\n",
    "            'rating': 4.5,\n",
    "            'difficulty': 3.0,\n",
    "            'cleaned_text': \"The professor was very helpful and explained concepts clearly.\"\n",
    "        }\n",
    "        \n",
    "        predicted_grade, confidence_interval = predictor.predict_grade(sample_features)\n",
    "        logger.info(f\"Example Prediction:\")\n",
    "        logger.info(f\"Predicted grade: {predicted_grade}\")\n",
    "        logger.info(f\"95% Confidence Interval: {confidence_interval}\")\n",
    "        \n",
    "        # Save feature importance\n",
    "        importance_df = predictor.get_feature_importance()\n",
    "        importance_df.to_csv(\"models/feature_importance.csv\", index=False)\n",
    "        \n",
    "        # Step 5: Visualization\n",
    "        logger.info(\"Creating visualizations...\")\n",
    "        visualizer = DataVisualizer()\n",
    "        \n",
    "        # Visualize training data\n",
    "        logger.info(\"Visualizing training data...\")\n",
    "        visualizer.plot_sentiment_distribution(processed_train_df)\n",
    "        visualizer.plot_grade_correlation(processed_train_df)\n",
    "        visualizer.plot_difficulty_rating(processed_train_df)\n",
    "        visualizer.plot_department_comparison(processed_train_df)\n",
    "        visualizer.plot_feature_importance(importance_df)\n",
    "        \n",
    "        # Visualize test data\n",
    "        logger.info(\"Visualizing test data...\")\n",
    "        visualizer.plot_sentiment_distribution(processed_test_df, suffix=\"_test\")\n",
    "        visualizer.plot_grade_correlation(processed_test_df, suffix=\"_test\")\n",
    "        visualizer.plot_difficulty_rating(processed_test_df, suffix=\"_test\")\n",
    "        \n",
    "        # Create correlation matrices\n",
    "        features = ['rating', 'difficulty', 'sentiment_score', 'grade_numerical']\n",
    "        visualizer.create_correlation_matrix(processed_train_df, features, suffix=\"_train\")\n",
    "        visualizer.create_correlation_matrix(processed_test_df, features, suffix=\"_test\")\n",
    "        \n",
    "        if 'date' in processed_train_df.columns:\n",
    "            visualizer.plot_sentiment_trends(processed_train_df, suffix=\"_train\")\n",
    "        if 'date' in processed_test_df.columns:\n",
    "            visualizer.plot_sentiment_trends(processed_test_df, suffix=\"_test\")\n",
    "        \n",
    "        # After model evaluation\n",
    "        metrics = predictor.evaluate_model(processed_test_df)\n",
    "        y_test = processed_test_df['grade_numerical']\n",
    "        X_test_scaled, _ = predictor.prepare_features(processed_test_df, is_training=False)\n",
    "        y_pred = predictor.model.predict(X_test_scaled)\n",
    "        visualizer.plot_actual_vs_predicted(y_test, y_pred, suffix='_test')\n",
    "        \n",
    "        logger.info(\"Analysis pipeline completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in analysis pipeline: {str(e)}\", exc_info=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
