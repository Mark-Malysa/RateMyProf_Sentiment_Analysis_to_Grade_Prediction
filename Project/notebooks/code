{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "This notebook performs exploratory data analysis on both the training data (existing dataset) and test data (newly scraped reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load training data\n",
    "training_df = pd.read_csv('../data/processed/processed_training_reviews.csv')\n",
    "print(f\"Training data shape: {training_df.shape}\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv('../data/processed/processed_test_reviews.csv')\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics and Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare basic statistics between training and test data\n",
    "print(\"Training Data Statistics:\")\n",
    "print(training_df.describe())\n",
    "print(\"\\nTest Data Statistics:\")\n",
    "print(test_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in training data:\")\n",
    "print(training_df.isnull().sum())\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare distributions of key variables\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Rating distribution\n",
    "sns.histplot(data=training_df, x='rating', bins=20, ax=axes[0, 0], label='Training')\n",
    "sns.histplot(data=test_df, x='rating', bins=20, ax=axes[0, 0], label='Test')\n",
    "axes[0, 0].set_title('Rating Distribution')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Difficulty distribution\n",
    "sns.histplot(data=training_df, x='difficulty', bins=20, ax=axes[0, 1], label='Training')\n",
    "sns.histplot(data=test_df, x='difficulty', bins=20, ax=axes[0, 1], label='Test')\n",
    "axes[0, 1].set_title('Difficulty Distribution')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Sentiment distribution\n",
    "sns.histplot(data=training_df, x='sentiment_score', bins=20, ax=axes[1, 0], label='Training')\n",
    "sns.histplot(data=test_df, x='sentiment_score', bins=20, ax=axes[1, 0], label='Test')\n",
    "axes[1, 0].set_title('Sentiment Score Distribution')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Grade distribution\n",
    "sns.histplot(data=training_df, x='grade_numerical', bins=20, ax=axes[1, 1], label='Training')\n",
    "sns.histplot(data=test_df, x='grade_numerical', bins=20, ax=axes[1, 1], label='Test')\n",
    "axes[1, 1].set_title('Grade Distribution')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create correlation matrices\n",
    "features = ['rating', 'difficulty', 'sentiment_score', 'grade_numerical']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Training data correlation\n",
    "corr_train = training_df[features].corr()\n",
    "sns.heatmap(corr_train, annot=True, cmap='coolwarm', center=0, ax=axes[0])\n",
    "axes[0].set_title('Training Data Correlation Matrix')\n",
    "\n",
    "# Test data correlation\n",
    "corr_test = test_df[features].corr()\n",
    "sns.heatmap(corr_test, annot=True, cmap='coolwarm', center=0, ax=axes[1])\n",
    "axes[1].set_title('Test Data Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Department Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare department distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Training data departments\n",
    "sns.countplot(data=training_df, x='department', ax=axes[0])\n",
    "axes[0].set_title('Training Data Department Distribution')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Test data departments\n",
    "sns.countplot(data=test_df, x='department', ax=axes[1])\n",
    "axes[1].set_title('Test Data Department Distribution')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time Analysis (if date information is available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if 'date' in training_df.columns and 'date' in test_df.columns:\n",
    "    # Convert date columns to datetime\n",
    "    training_df['date'] = pd.to_datetime(training_df['date'])\n",
    "    test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "    \n",
    "    # Create time series plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Rating trends\n",
    "    training_df.groupby('date')['rating'].mean().plot(ax=axes[0, 0], label='Training')\n",
    "    test_df.groupby('date')['rating'].mean().plot(ax=axes[0, 0], label='Test')\n",
    "    axes[0, 0].set_title('Average Rating Over Time')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Sentiment trends\n",
    "    training_df.groupby('date')['sentiment_score'].mean().plot(ax=axes[0, 1], label='Training')\n",
    "    test_df.groupby('date')['sentiment_score'].mean().plot(ax=axes[0, 1], label='Test')\n",
    "    axes[0, 1].set_title('Average Sentiment Over Time')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Review count trends\n",
    "    training_df.groupby('date').size().plot(ax=axes[1, 0], label='Training')\n",
    "    test_df.groupby('date').size().plot(ax=axes[1, 0], label='Test')\n",
    "    axes[1, 0].set_title('Number of Reviews Over Time')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Grade trends\n",
    "    training_df.groupby('date')['grade_numerical'].mean().plot(ax=axes[1, 1], label='Training')\n",
    "    test_df.groupby('date')['grade_numerical'].mean().plot(ax=axes[1, 1], label='Test')\n",
    "    axes[1, 1].set_title('Average Grade Over Time')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare review text lengths\n",
    "training_df['text_length'] = training_df['text'].str.len()\n",
    "test_df['text_length'] = test_df['text'].str.len()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=training_df, x='text_length', bins=50, label='Training')\n",
    "sns.histplot(data=test_df, x='text_length', bins=50, label='Test')\n",
    "plt.title('Distribution of Review Text Lengths')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data vs Test Data Comparison\n",
    "\n",
    "1. **Data Size and Coverage**:\n",
    "   - Training data size: {training_df.shape[0]} reviews\n",
    "   - Test data size: {test_df.shape[0]} reviews\n",
    "   - Department coverage comparison\n",
    "   \n",
    "2. **Distribution Similarities/Differences**:\n",
    "   - Rating distributions\n",
    "   - Difficulty distributions\n",
    "   - Sentiment score distributions\n",
    "   - Grade distributions\n",
    "   \n",
    "3. **Correlation Patterns**:\n",
    "   - Compare correlation matrices\n",
    "   - Identify consistent patterns\n",
    "   - Note any significant differences\n",
    "   \n",
    "4. **Temporal Patterns** (if date data available):\n",
    "   - Review frequency over time\n",
    "   - Rating trends\n",
    "   - Sentiment trends\n",
    "   - Grade trends\n",
    "   \n",
    "5. **Text Analysis**:\n",
    "   - Review length distributions\n",
    "   - Sentiment patterns\n",
    "   - Common themes\n",
    "   \n",
    "6. **Potential Biases or Limitations**:\n",
    "   - Data collection differences\n",
    "   - Time period differences\n",
    "   - Department coverage differences\n",
    "   - Sample size considerations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}